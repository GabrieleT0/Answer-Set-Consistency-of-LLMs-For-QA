{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89317569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_json_scores(folder):\n",
    "    \"\"\"\n",
    "    Reads all JSON files in the given folder and computes the average score for each file.\n",
    "    Assumes each JSON file is a dictionary of numeric values.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with columns: Filename, Average Score, Count of 1s, Ratio of 1s\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(folder, filename)\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        values = list(data.values())\n",
    "        if not values:\n",
    "            continue\n",
    "\n",
    "        avg_score = sum(values) / len(values)\n",
    "        count_ones = sum(1 for v in values if v == 1)\n",
    "        ratio_ones = count_ones / len(values)\n",
    "\n",
    "        rows.append({\n",
    "            \"Filename\": filename,\n",
    "            \"Average Score\": round(avg_score, 4),\n",
    "            \"Count of 1s\": count_ones,\n",
    "            \"Size\": len(values)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage\n",
    "# df = summarize_json_scores(\"../data/evaluation_results/\")\n",
    "# print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ad737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Filename  Average Score  \\\n",
      "0  Containment_gpt-4.1-mini-2025-04-14_spinach.ts...         0.9800   \n",
      "1  Containment_gpt-4.1-nano-2025-04-14_spinach.ts...         0.4000   \n",
      "2               Containment_gpt-4.1_spinach.tsv.json         0.9933   \n",
      "3    Equivalence_gpt-4.1-2025-04-14_spinach.tsv.json         0.9667   \n",
      "4  Equivalence_gpt-4.1-mini-2025-04-14_spinach.ts...         0.9600   \n",
      "5   Equivalence_gpt-4.1-nano-2025-04-14_spinach.json         0.9467   \n",
      "6          Minus_gpt-4.1-2025-04-14_spinach.tsv.json         0.4533   \n",
      "7     Minus_gpt-4.1-mini-2025-04-14_spinach.tsv.json         0.4800   \n",
      "8     Minus_gpt-4.1-nano-2025-04-14_spinach.tsv.json         0.0133   \n",
      "\n",
      "   Count of 1s  Size  \n",
      "0          147   150  \n",
      "1           60   150  \n",
      "2          149   150  \n",
      "3          145   150  \n",
      "4          144   150  \n",
      "5          142   150  \n",
      "6           68   150  \n",
      "7           72   150  \n",
      "8            2   150  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "datasets = ['spinach']\n",
    "\n",
    "for dataset in datasets:\n",
    "    folder = f'../data/answers/zero-shot/{dataset}/relation-classification/'\n",
    "    df = summarize_json_scores(folder)\n",
    "    df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864ee3d",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fd45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Calculate the Jaccard similarity between two sets.\"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "# For the subset-superset check\n",
    "def is_subset(set1, set2):\n",
    "    \"\"\"Check if set1 is a subset of set2.\"\"\"\n",
    "    return set1.issubset(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c65423f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def compute_similarity(\n",
    "    model: str,\n",
    "    task: str,\n",
    "    action: str,\n",
    "    base_dir: str = '../data/answers',\n",
    "    output_dir: str = '.',\n",
    "    star = False\n",
    "):\n",
    "    if star:\n",
    "        prefix = '*'\n",
    "    else:\n",
    "        prefix = ''\n",
    "    # Build file paths\n",
    "    action_word = action+ \"\"\n",
    "    # if action == \"wikidata\":\n",
    "    #     action_word = \"wikidata_\"\n",
    "    \n",
    "    ql1_path = os.path.join(base_dir, task, f'{prefix}Q1_{task}_answers_{action_word}{model}.json')\n",
    "    ql2_path = os.path.join(base_dir, task, f'{prefix}Q2_{task}_answers_{action_word}{model}.json')\n",
    "\n",
    "    ql3_path = None\n",
    "    if task == \"minus\":\n",
    "        ql3_path = os.path.join(base_dir, task, f'{prefix}Q4_{task}_answers_{action_word}{model}.json')\n",
    "        ql1_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q1_sup-sub_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q2_sup-sub_answers_{action_word}{model}.json')\n",
    "\n",
    "    # Load data\n",
    "    try: \n",
    "        with open(ql1_path, 'r', encoding='utf-8') as f:\n",
    "            ql1_answers = json.load(f)\n",
    "        with open(ql2_path, 'r', encoding='utf-8') as f:\n",
    "            ql2_answers = json.load(f)\n",
    "        if ql3_path is not None:\n",
    "            with open(ql3_path, 'r', encoding='utf-8') as f:\n",
    "                ql3_answers = json.load(f)\n",
    "        else:\n",
    "            ql3_answers = None\n",
    "    except:\n",
    "        print(f\"Error loading files: {ql1_path}, {ql2_path}, {ql3_path}\")   \n",
    "        return None\n",
    "    # Compute metrics per question\n",
    "    similarity_scores = {}\n",
    "    if task == \"minus\":\n",
    "        # For minus task, we need to compare ql1 and ql2 with ql3\n",
    "        for qid, ans3 in ql3_answers.items():\n",
    "            set3 = set(ans3)\n",
    "            qid = str(int(qid) + 1)\n",
    "            set_a = set(ql1_answers.get(qid, []))\n",
    "            set_b = set(ql2_answers.get(qid, [])) \n",
    "            set_c =  set_b - set_a\n",
    "            sim = jaccard_similarity(set3, set_c)\n",
    "            is_empty = int(len(set3) == 0 and len(set_c) == 0)\n",
    "            binary_eq = int(set_c == set3)\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "    else:\n",
    "        for qid, ans1 in ql1_answers.items():\n",
    "            set1 = set(ans1)\n",
    "            set2 = set(ql2_answers.get(qid, []))\n",
    "            sim = jaccard_similarity(set1, set2)\n",
    "            is_empty = int(len(set1) == 0 and len(set2) == 0)\n",
    "            binary_eq = int(set1 == set2)\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "\n",
    "    # Create DataFrame\n",
    "    sim_df = pd.DataFrame.from_dict(\n",
    "        similarity_scores,\n",
    "        orient='index',\n",
    "        columns=['JaccardSimilarity', 'IsEmptySet', 'BinaryEqual']\n",
    "    )\n",
    "\n",
    "    # Ensure index is a column\n",
    "    sim_df = sim_df.reset_index().rename(columns={'index': 'QuestionID'})\n",
    "\n",
    "    # Save to TSV\n",
    "    output_filename = f'{prefix}{task}_{model}_{action}.tsv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    sim_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Saved similarity results to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6a280277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = ['gpt-4.1-nano-2025-04-14',\"gpt-4.1-mini-2025-04-14\",\"gpt-4.1-2025-04-14\"]\n",
    "task = ['equal', 'sup-sub', \"minus\"]\n",
    "action = [\"\"]\n",
    "operations = ['zero-shot',\"follow_up_fixing\",\"rel_classification_and_questions\"]\n",
    "for dataset in datasets:\n",
    "    for m in model:\n",
    "        for t in task:\n",
    "            for a in action:\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                )\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                    star=False\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78492763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Action</th>\n",
       "      <th>Average_All</th>\n",
       "      <th>Average_NoEmpty</th>\n",
       "      <th>Ratio_empty</th>\n",
       "      <th>Binary_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.4065</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.4298</td>\n",
       "      <td>0.4884</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.3925</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Task                    Model          Action  Average_All  \\\n",
       "0     equal       gpt-4.1-2025-04-14                       0.7438   \n",
       "1     equal       gpt-4.1-2025-04-14        wikidata       0.7980   \n",
       "2     equal       gpt-4.1-2025-04-14          fixing       0.9275   \n",
       "3     equal  gpt-4.1-mini-2025-04-14                       0.7116   \n",
       "4     equal  gpt-4.1-mini-2025-04-14        wikidata       0.7297   \n",
       "5     equal  gpt-4.1-mini-2025-04-14  classAndAnswer       0.8755   \n",
       "6     equal  gpt-4.1-mini-2025-04-14          fixing       0.9138   \n",
       "7     equal  gpt-4.1-nano-2025-04-14                       0.6025   \n",
       "8     equal  gpt-4.1-nano-2025-04-14        wikidata       0.6103   \n",
       "9     equal  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0155   \n",
       "10    equal  gpt-4.1-nano-2025-04-14          fixing       0.6881   \n",
       "11    minus       gpt-4.1-2025-04-14                       0.0000   \n",
       "12    minus       gpt-4.1-2025-04-14        wikidata       0.0000   \n",
       "13    minus  gpt-4.1-mini-2025-04-14                       0.0000   \n",
       "14    minus  gpt-4.1-mini-2025-04-14        wikidata       0.0000   \n",
       "15    minus  gpt-4.1-mini-2025-04-14  classAndAnswer       0.0000   \n",
       "16    minus  gpt-4.1-mini-2025-04-14          fixing       0.0000   \n",
       "17    minus  gpt-4.1-nano-2025-04-14                       0.0000   \n",
       "18    minus  gpt-4.1-nano-2025-04-14        wikidata       0.0000   \n",
       "19    minus  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0000   \n",
       "20    minus  gpt-4.1-nano-2025-04-14          fixing       0.0000   \n",
       "21  sup-sub       gpt-4.1-2025-04-14                       0.4065   \n",
       "22  sup-sub       gpt-4.1-2025-04-14        wikidata       0.4298   \n",
       "23  sup-sub  gpt-4.1-mini-2025-04-14                       0.4312   \n",
       "24  sup-sub  gpt-4.1-mini-2025-04-14        wikidata       0.4368   \n",
       "25  sup-sub  gpt-4.1-mini-2025-04-14  classAndAnswer       0.4802   \n",
       "26  sup-sub  gpt-4.1-mini-2025-04-14          fixing       0.5036   \n",
       "27  sup-sub  gpt-4.1-nano-2025-04-14                       0.3626   \n",
       "28  sup-sub  gpt-4.1-nano-2025-04-14        wikidata       0.3925   \n",
       "29  sup-sub  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0593   \n",
       "30  sup-sub  gpt-4.1-nano-2025-04-14          fixing       0.3350   \n",
       "\n",
       "    Average_NoEmpty  Ratio_empty  Binary_count  \n",
       "0            0.7748       0.0400        0.4733  \n",
       "1            0.8199       0.0267        0.5000  \n",
       "2            0.9730       0.0467        0.9067  \n",
       "3            0.7907       0.1000        0.5067  \n",
       "4            0.7549       0.0333        0.4400  \n",
       "5            0.9800       0.1067        0.9400  \n",
       "6            0.9453       0.0333        0.8533  \n",
       "7            0.7172       0.1600        0.3467  \n",
       "8            0.7042       0.1333        0.3333  \n",
       "9            0.7755       0.9800        0.8333  \n",
       "10           0.9469       0.2733        0.7600  \n",
       "11              NaN       1.0000        0.0800  \n",
       "12              NaN       1.0000        0.0600  \n",
       "13              NaN       1.0000        0.0133  \n",
       "14              NaN       1.0000        0.0133  \n",
       "15              NaN       1.0000        0.2467  \n",
       "16              NaN       1.0000        0.1200  \n",
       "17              NaN       1.0000        0.0867  \n",
       "18              NaN       1.0000        0.0800  \n",
       "19              NaN       1.0000        0.6867  \n",
       "20              NaN       1.0000        0.1267  \n",
       "21           0.4655       0.1267        0.1067  \n",
       "22           0.4884       0.1200        0.0733  \n",
       "23           0.5216       0.1733        0.1467  \n",
       "24           0.5241       0.1667        0.1333  \n",
       "25           0.5672       0.1533        0.1933  \n",
       "26           0.5474       0.0800        0.1267  \n",
       "27           0.5280       0.3133        0.1667  \n",
       "28           0.5210       0.2467        0.1600  \n",
       "29           0.5925       0.9000        0.7533  \n",
       "30           0.5776       0.4200        0.2067  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_evaluation_results(folder):\n",
    "    \"\"\"\n",
    "    Summarize per-question TSV evaluation files in a folder.\n",
    "    Expects filenames in the format: task-model-action.tsv\n",
    "    and each TSV contains columns: QuestionID, JaccardSimilarity, IsEmptySet, BinaryEqual\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if not filename.endswith(\".tsv\"):\n",
    "            continue\n",
    "\n",
    "        # Extract metadata from filename\n",
    "        base = filename[:-4]  # remove .tsv\n",
    "        parts = base.split('_')\n",
    "        task = parts[0]\n",
    "        action = parts[-1]\n",
    "        model = parts[1]\n",
    "\n",
    "        # Read TSV\n",
    "        df = pd.read_csv(os.path.join(folder, filename), sep='\\t')\n",
    "\n",
    "        # Ensure JaccardSimilarity column exists\n",
    "        if 'JaccardSimilarity' not in df.columns:\n",
    "            raise ValueError(f\"Missing 'JaccardSimilarity' in {filename}\")\n",
    "\n",
    "        # Compute overall average\n",
    "        avg_all = df['JaccardSimilarity'].mean()\n",
    "\n",
    "        # Identify empty (zero) Jaccard entries\n",
    "        is_empty = df['JaccardSimilarity'] == 0\n",
    "        ratio_empty = is_empty.mean()\n",
    "\n",
    "        # Average excluding empty entries\n",
    "        non_empty = df.loc[~is_empty, 'JaccardSimilarity']\n",
    "        avg_non_empty = non_empty.mean() if not non_empty.empty else float('nan')\n",
    "\n",
    "        # Binary count: proportion where BinaryEqual == 1\n",
    "        if 'BinaryEqual' in df.columns:\n",
    "            binary_count = (df['BinaryEqual'] == 1).mean()\n",
    "        else:\n",
    "            binary_count = float('nan')\n",
    "\n",
    "        rows.append({\n",
    "            \"Task\": task,\n",
    "            \"Model\": model,\n",
    "            \"Action\": action,\n",
    "            \"Average_All\": round(avg_all, 4),\n",
    "            \"Average_NoEmpty\": round(avg_non_empty, 4),\n",
    "            \"Ratio_empty\": round(ratio_empty, 4),\n",
    "            \"Binary_count\": round(binary_count, 4),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage:\n",
    "df = summarize_evaluation_results(\"../data/evaluation_results/spinach/\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b1220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
