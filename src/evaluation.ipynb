{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89317569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_json_scores(folder):\n",
    "    \"\"\"\n",
    "    Reads all JSON files in the given folder and computes the average score for each file.\n",
    "    Assumes each JSON file is a dictionary of numeric values.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with columns: Filename, Average Score, Count of 1s, Ratio of 1s\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(folder, filename)\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        values = list(data.values())\n",
    "        if not values:\n",
    "            continue\n",
    "\n",
    "        avg_score = sum(values) / len(values)\n",
    "        count_ones = sum(1 for v in values if v == 1)\n",
    "        ratio_ones = count_ones / len(values)\n",
    "\n",
    "        rows.append({\n",
    "            \"Filename\": filename,\n",
    "            \"Average Score\": round(avg_score, 4),\n",
    "            \"Count of 1s\": count_ones,\n",
    "            \"Size\": len(values)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage\n",
    "# df = summarize_json_scores(\"../data/evaluation_results/\")\n",
    "# print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181ad737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Filename  Average Score  Count of 1s  Size\n",
      "0  Containment_gpt-4.1-mini-2025-04-14.json         0.9800          147   150\n",
      "1  Containment_gpt-4.1-nano-2025-04-14.json         0.4000           60   150\n",
      "2                  Containment_gpt-4.1.json         0.9933          149   150\n",
      "3       Equivalence_gpt-4.1-2025-04-14.json         0.9667          145   150\n",
      "4  Equivalence_gpt-4.1-mini-2025-04-14.json         0.9600          144   150\n",
      "5  Equivalence_gpt-4.1-nano-2025-04-14.json         0.9467          142   150\n",
      "6             Minus_gpt-4.1-2025-04-14.json         0.4533           68   150\n",
      "7        Minus_gpt-4.1-mini-2025-04-14.json         0.4800           72   150\n",
      "8        Minus_gpt-4.1-nano-2025-04-14.json         0.0133            2   150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "datasets = ['spinach']\n",
    "\n",
    "for dataset in datasets:\n",
    "    folder = f'../data/answers/zero-shot/{dataset}/relation-classification/'\n",
    "    df = summarize_json_scores(folder)\n",
    "    print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864ee3d",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fd45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Calculate the Jaccard similarity between two sets.\"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "# For the subset-superset check\n",
    "def is_subset(set1, set2):\n",
    "    \"\"\"Check if set1 is a subset of set2.\"\"\"\n",
    "    return set1.issubset(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65423f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def compute_similarity(\n",
    "    model: str,\n",
    "    task: str,\n",
    "    action: str,\n",
    "    base_dir: str = '../data/answers',\n",
    "    output_dir: str = '.',\n",
    "    star = False\n",
    "):\n",
    "    if star:\n",
    "        prefix = '*'\n",
    "    else:\n",
    "        prefix = ''\n",
    "    # Build file paths\n",
    "    action_word = action+ \"\"\n",
    "    #if action == \"wikidata\":\n",
    "    #     action_word = \"wikidata_\"\n",
    "    \n",
    "    ql1_path = os.path.join(base_dir, task, f'{prefix}Q1_{task}_answers_{action_word}{model}.json')\n",
    "    ql2_path = os.path.join(base_dir, task, f'{prefix}Q2_{task}_answers_{action_word}{model}.json')\n",
    "\n",
    "    ql3_path = os.path.join(base_dir, task, f'{prefix}Q4_{task}_answers_{action_word}{model}.json')\n",
    "    if task == \"minus\":\n",
    "        ql3_path = os.path.join(base_dir, task, f'{prefix}Q4_{task}_answers_{action_word}{model}.json')\n",
    "        ql1_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q1_sup-sub_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q2_sup-sub_answers_{action_word}{model}.json')\n",
    "\n",
    "    # Load data\n",
    "    try: \n",
    "        with open(ql1_path, 'r', encoding='utf-8') as f:\n",
    "            ql1_answers = json.load(f)\n",
    "        with open(ql2_path, 'r', encoding='utf-8') as f:\n",
    "            ql2_answers = json.load(f)\n",
    "        if ql3_path is not None:\n",
    "            with open(ql3_path, 'r', encoding='utf-8') as f:\n",
    "                ql3_answers = json.load(f)\n",
    "        else:\n",
    "            ql3_answers = None\n",
    "    except:\n",
    "        print(f\"Error loading files: {ql1_path}, {ql2_path}, {ql3_path}\")   \n",
    "        return None\n",
    "    # Compute metrics per question\n",
    "    similarity_scores = {}\n",
    "    if task == \"minus\":\n",
    "        # For minus task, we need to compare ql1 and ql2 with ql3\n",
    "        for qid, ans3 in ql3_answers.items():\n",
    "            set3 = set(ans3)\n",
    "            #qid = str(int(qid) + 1)\n",
    "            set_a = set(ql1_answers.get(qid, []))\n",
    "            set_b = set(ql2_answers.get(qid, [])) \n",
    "            set_c =  set_a - set_b \n",
    "            sim = jaccard_similarity(set3, set_c)\n",
    "            is_empty = int(len(set3) == 0 and len(set_c) == 0)\n",
    "            binary_eq = int(set_c == set3)\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "    else:\n",
    "        for qid, ans1 in ql1_answers.items():\n",
    "            set1 = set(ans1)\n",
    "            set2 = set(ql2_answers.get(qid, []))\n",
    "            is_empty = int(len(set1) == 0 and len(set2) == 0)\n",
    "            if task == \"equal\":\n",
    "                sim = jaccard_similarity(set1, set2)\n",
    "                binary_eq = int(set1 == set2)\n",
    "            else:\n",
    "                set_c = set(ql3_answers.get(qid, []))\n",
    "                union = set2.union(set_c) \n",
    "                sim = jaccard_similarity(set1, union)\n",
    "                binary_eq = int(is_subset(set2, set1))\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "\n",
    "    # Create DataFrame\n",
    "    sim_df = pd.DataFrame.from_dict(\n",
    "        similarity_scores,\n",
    "        orient='index',\n",
    "        columns=['JaccardSimilarity', 'IsEmptySet', 'BinaryEqual']\n",
    "    )\n",
    "\n",
    "    # Ensure index is a column\n",
    "    sim_df = sim_df.reset_index().rename(columns={'index': 'QuestionID'})\n",
    "\n",
    "    # Save to TSV\n",
    "    output_filename = f'{prefix}{task}_{model}_{action}.tsv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    sim_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Saved similarity results to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a280277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-nano-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-nano-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-nano-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-nano-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-nano-2025-04-14.json\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-mini-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-mini-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-mini-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-mini-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-mini-2025-04-14.json\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/equal/Q1_equal_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q2_equal_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/equal/Q4_equal_answers_gpt-4.1-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-2025-04-14.json\n",
      "Error loading files: ../data/answers/zero-shot/spinach/sup-sub/Q1_sup-sub_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q2_sup-sub_answers_gpt-4.1-2025-04-14.json, ../data/answers/zero-shot/spinach/sup-sub/Q4_sup-sub_answers_gpt-4.1-2025-04-14.json\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = ['gpt-4.1-nano-2025-04-14',\"gpt-4.1-mini-2025-04-14\",\"gpt-4.1-2025-04-14\"]\n",
    "task = ['equal', 'sup-sub', \"minus\"]\n",
    "action = [\"\"]\n",
    "operations = ['zero-shot',\"follow_up_fixing\",\"rel_classification_and_questions\"]\n",
    "datasets = ['spinach']\n",
    "for dataset in datasets:\n",
    "    for m in model:\n",
    "        for t in task:\n",
    "            for a in action:\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                )\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                    star=False\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78492763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Action</th>\n",
       "      <th>Average_All</th>\n",
       "      <th>Average_NoEmpty</th>\n",
       "      <th>Ratio_empty</th>\n",
       "      <th>Binary_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.9485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.3465</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.3664</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.8014</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.5867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.0667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.4933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.4065</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.4298</td>\n",
       "      <td>0.4884</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.4969</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.3925</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Task                    Model          Action  Average_All  \\\n",
       "0     equal       gpt-4.1-2025-04-14                       0.7438   \n",
       "1     equal       gpt-4.1-2025-04-14        wikidata       0.7980   \n",
       "2     equal       gpt-4.1-2025-04-14  classAndAnswer       0.9249   \n",
       "3     equal       gpt-4.1-2025-04-14          fixing       0.9275   \n",
       "4     equal  gpt-4.1-mini-2025-04-14                       0.7116   \n",
       "5     equal  gpt-4.1-mini-2025-04-14        wikidata       0.7297   \n",
       "6     equal  gpt-4.1-mini-2025-04-14  classAndAnswer       0.8755   \n",
       "7     equal  gpt-4.1-mini-2025-04-14          fixing       0.9138   \n",
       "8     equal  gpt-4.1-nano-2025-04-14                       0.6025   \n",
       "9     equal  gpt-4.1-nano-2025-04-14        wikidata       0.6103   \n",
       "10    equal  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0155   \n",
       "11    equal  gpt-4.1-nano-2025-04-14          fixing       0.6881   \n",
       "12    minus       gpt-4.1-2025-04-14                       0.3465   \n",
       "13    minus       gpt-4.1-2025-04-14        wikidata       0.3664   \n",
       "14    minus       gpt-4.1-2025-04-14  classAndAnswer       0.6251   \n",
       "15    minus       gpt-4.1-2025-04-14          fixing       0.6980   \n",
       "16    minus  gpt-4.1-mini-2025-04-14                       0.2616   \n",
       "17    minus  gpt-4.1-mini-2025-04-14        wikidata       0.2763   \n",
       "18    minus  gpt-4.1-mini-2025-04-14  classAndAnswer       0.5355   \n",
       "19    minus  gpt-4.1-mini-2025-04-14          fixing       0.5816   \n",
       "20    minus  gpt-4.1-nano-2025-04-14                       0.1749   \n",
       "21    minus  gpt-4.1-nano-2025-04-14        wikidata       0.1955   \n",
       "22    minus  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0520   \n",
       "23    minus  gpt-4.1-nano-2025-04-14          fixing       0.2410   \n",
       "24  sup-sub       gpt-4.1-2025-04-14                       0.4065   \n",
       "25  sup-sub       gpt-4.1-2025-04-14        wikidata       0.4298   \n",
       "26  sup-sub       gpt-4.1-2025-04-14  classAndAnswer       0.4919   \n",
       "27  sup-sub       gpt-4.1-2025-04-14          fixing       0.4969   \n",
       "28  sup-sub  gpt-4.1-mini-2025-04-14                       0.4312   \n",
       "29  sup-sub  gpt-4.1-mini-2025-04-14        wikidata       0.4368   \n",
       "30  sup-sub  gpt-4.1-mini-2025-04-14  classAndAnswer       0.4802   \n",
       "31  sup-sub  gpt-4.1-mini-2025-04-14          fixing       0.5036   \n",
       "32  sup-sub  gpt-4.1-nano-2025-04-14                       0.3626   \n",
       "33  sup-sub  gpt-4.1-nano-2025-04-14        wikidata       0.3925   \n",
       "34  sup-sub  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0593   \n",
       "35  sup-sub  gpt-4.1-nano-2025-04-14          fixing       0.3350   \n",
       "\n",
       "    Average_NoEmpty  Ratio_empty  Binary_count  \n",
       "0            0.7748       0.0400        0.4733  \n",
       "1            0.8199       0.0267        0.5000  \n",
       "2            0.9751       0.0515        0.9485  \n",
       "3            0.9730       0.0467        0.9067  \n",
       "4            0.7907       0.1000        0.5067  \n",
       "5            0.7549       0.0333        0.4400  \n",
       "6            0.9800       0.1067        0.9400  \n",
       "7            0.9453       0.0333        0.8533  \n",
       "8            0.7172       0.1600        0.3467  \n",
       "9            0.7042       0.1333        0.3333  \n",
       "10           0.7755       0.9800        0.8333  \n",
       "11           0.9469       0.2733        0.7600  \n",
       "12           0.5414       0.3600        0.1533  \n",
       "13           0.5726       0.3600        0.1667  \n",
       "14           0.8014       0.2200        0.5867  \n",
       "15           0.8512       0.1800        0.6333  \n",
       "16           0.4563       0.4267        0.0933  \n",
       "17           0.4555       0.3933        0.0667  \n",
       "18           0.7952       0.3267        0.5400  \n",
       "19           0.7859       0.2600        0.4933  \n",
       "20           0.4300       0.5933        0.0933  \n",
       "21           0.4190       0.5333        0.0800  \n",
       "22           0.7806       0.9333        0.8200  \n",
       "23           0.6127       0.6067        0.2600  \n",
       "24           0.4655       0.1267        0.1067  \n",
       "25           0.4884       0.1200        0.0733  \n",
       "26           0.5426       0.0933        0.1733  \n",
       "27           0.5440       0.0867        0.1467  \n",
       "28           0.5216       0.1733        0.1467  \n",
       "29           0.5241       0.1667        0.1333  \n",
       "30           0.5672       0.1533        0.1933  \n",
       "31           0.5474       0.0800        0.1267  \n",
       "32           0.5280       0.3133        0.1667  \n",
       "33           0.5210       0.2467        0.1600  \n",
       "34           0.5925       0.9000        0.7533  \n",
       "35           0.5776       0.4200        0.2067  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def compute_similarity(\n",
    "    model: str,\n",
    "    task: str,\n",
    "    action: str,\n",
    "    base_dir: str = '../data/answers',\n",
    "    output_dir: str = '.',\n",
    "    star = False\n",
    "):\n",
    "    if star:\n",
    "        prefix = '*'\n",
    "    else:\n",
    "        prefix = ''\n",
    "    # Build file paths\n",
    "    action_word = action+ \"\"\n",
    "    #if action == \"wikidata\":\n",
    "    #     action_word = \"wikidata_\"\n",
    "    \n",
    "    ql1_path = os.path.join(base_dir, task, f'{prefix}Q1_{task}_answers_{action_word}{model}.json')\n",
    "    ql2_path = os.path.join(base_dir, task, f'{prefix}Q2_{task}_answers_{action_word}{model}.json')\n",
    "\n",
    "    ql3_path = os.path.join(base_dir, 'minus', f'{prefix}Q4_minus_answers_{action_word}{model}.json')\n",
    "    if task == \"minus\":\n",
    "        ql3_path = os.path.join(base_dir, task, f'{prefix}Q4_{task}_answers_{action_word}{model}.json')\n",
    "        ql1_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q1_sup-sub_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q2_sup-sub_answers_{action_word}{model}.json')\n",
    "\n",
    "    # Load data\n",
    "    try: \n",
    "        with open(ql1_path, 'r', encoding='utf-8') as f:\n",
    "            ql1_answers = json.load(f)\n",
    "        with open(ql2_path, 'r', encoding='utf-8') as f:\n",
    "            ql2_answers = json.load(f)\n",
    "        if ql3_path is not None:\n",
    "            with open(ql3_path, 'r', encoding='utf-8') as f:\n",
    "                ql3_answers = json.load(f)\n",
    "        else:\n",
    "            ql3_answers = None\n",
    "    except:\n",
    "        print(f\"Error loading files: {ql1_path}, {ql2_path}, {ql3_path}\")   \n",
    "        return None\n",
    "    # Compute metrics per question\n",
    "    similarity_scores = {}\n",
    "    if task == \"minus\":\n",
    "        # For minus task, we need to compare ql1 and ql2 with ql3\n",
    "        for qid, ans3 in ql3_answers.items():\n",
    "            set3 = set(ans3)\n",
    "            #qid = str(int(qid) + 1)\n",
    "            set_a = set(ql1_answers.get(qid, []))\n",
    "            set_b = set(ql2_answers.get(qid, [])) \n",
    "            set_c =  set_a - set_b \n",
    "            sim = jaccard_similarity(set3, set_c)\n",
    "            is_empty = int(len(set3) == 0 and len(set_c) == 0)\n",
    "            binary_eq = int(set_c == set3)\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "    else:\n",
    "        for qid, ans1 in ql1_answers.items():\n",
    "            set1 = set(ans1)\n",
    "            set2 = set(ql2_answers.get(qid, []))\n",
    "            is_empty = int(len(set1) == 0 and len(set2) == 0)\n",
    "            if task == \"equal\":\n",
    "                sim = jaccard_similarity(set1, set2)\n",
    "                binary_eq = int(set1 == set2)\n",
    "            else:\n",
    "                set_c = set(ql3_answers.get(qid, []))\n",
    "                union = set2.union(set_c) \n",
    "                sim = jaccard_similarity(set1, union)\n",
    "                binary_eq = int(is_subset(set2, set1))\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "\n",
    "    # Create DataFrame\n",
    "    sim_df = pd.DataFrame.from_dict(\n",
    "        similarity_scores,\n",
    "        orient='index',\n",
    "        columns=['JaccardSimilarity', 'IsEmptySet', 'BinaryEqual']\n",
    "    )\n",
    "\n",
    "    # Ensure index is a column\n",
    "    sim_df = sim_df.reset_index().rename(columns={'index': 'QuestionID'})\n",
    "\n",
    "    # Save to TSV\n",
    "    output_filename = f'{prefix}{task}_{model}_{action}.tsv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    sim_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Saved similarity results to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b1220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
