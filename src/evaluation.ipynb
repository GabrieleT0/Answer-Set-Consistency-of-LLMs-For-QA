{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89317569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_json_scores(folder):\n",
    "    \"\"\"\n",
    "    Reads all JSON files in the given folder and computes the average score for each file.\n",
    "    Assumes each JSON file is a dictionary of numeric values.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with columns: Filename, Average Score, Count of 1s, Ratio of 1s\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(folder, filename)\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        values = list(data.values())\n",
    "        if not values:\n",
    "            continue\n",
    "\n",
    "        avg_score = sum(values) / len(values)\n",
    "        count_ones = sum(1 for v in values if v == 1)\n",
    "        ratio_ones = count_ones / len(values)\n",
    "\n",
    "        rows.append({\n",
    "            \"Filename\": filename,\n",
    "            \"Average Score\": round(avg_score, 4),\n",
    "            \"Count of 1s\": count_ones,\n",
    "            \"Size\": len(values)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage\n",
    "# df = summarize_json_scores(\"../data/evaluation_results/\")\n",
    "# print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181ad737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Filename  Average Score  Count of 1s  Size\n",
      "0  Containment_gpt-4.1-mini-2025-04-14.json         0.9800          147   150\n",
      "1  Containment_gpt-4.1-nano-2025-04-14.json         0.4000           60   150\n",
      "2                  Containment_gpt-4.1.json         0.9933          149   150\n",
      "3       Equivalence_gpt-4.1-2025-04-14.json         0.9667          145   150\n",
      "4  Equivalence_gpt-4.1-mini-2025-04-14.json         0.9600          144   150\n",
      "5  Equivalence_gpt-4.1-nano-2025-04-14.json         0.9467          142   150\n",
      "6             Minus_gpt-4.1-2025-04-14.json         0.4533           68   150\n",
      "7        Minus_gpt-4.1-mini-2025-04-14.json         0.4800           72   150\n",
      "8        Minus_gpt-4.1-nano-2025-04-14.json         0.0133            2   150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "datasets = ['spinach']\n",
    "\n",
    "for dataset in datasets:\n",
    "    folder = f'../data/answers/zero-shot/{dataset}/relation-classification/'\n",
    "    df = summarize_json_scores(folder)\n",
    "    print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864ee3d",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fd45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Calculate the Jaccard similarity between two sets.\"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "# For the subset-superset check\n",
    "def is_subset(set1, set2):\n",
    "    \"\"\"Check if set1 is a subset of set2.\"\"\"\n",
    "    return set1.issubset(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65423f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def compute_similarity(\n",
    "    model: str,\n",
    "    task: str,\n",
    "    action: str,\n",
    "    base_dir: str = '../data/answers',\n",
    "    output_dir: str = '.',\n",
    "    star = False\n",
    "):\n",
    "    if star:\n",
    "        prefix = '*'\n",
    "    else:\n",
    "        prefix = ''\n",
    "    # Build file paths\n",
    "    action_word = action+ \"\"\n",
    "    #if action == \"wikidata\":\n",
    "    #     action_word = \"wikidata_\"\n",
    "    \n",
    "    if task == \"equal\":\n",
    "        ql1_path = os.path.join(base_dir, task, f'{prefix}Q1_{task}_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, task, f'{prefix}Q2_{task}_answers_{action_word}{model}.json')\n",
    "    if task == \"minus\":\n",
    "        ql3_path = os.path.join(base_dir, task, f'{prefix}Q4_{task}_answers_{action_word}{model}.json')\n",
    "        ql1_path = os.path.join(base_dir, \"equal\", f'{prefix}Q1_equal_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, \"sup-sub\", f'{prefix}Q3_sup-sub_answers_{action_word}{model}.json')\n",
    "    if task == \"sup-sub\":\n",
    "        ql1_path = os.path.join(base_dir, 'equal', f'{prefix}Q1_equal_answers_{action_word}{model}.json')\n",
    "        ql2_path = os.path.join(base_dir, 'sup-sub', f'{prefix}Q3_sup-sub_answers_{action_word}{model}.json')\n",
    "        ql3_path = os.path.join(base_dir, 'minus', f'{prefix}Q4_minus_answers_{action_word}{model}.json')\n",
    "\n",
    "    # Load data\n",
    "    try: \n",
    "        with open(ql1_path, 'r', encoding='utf-8') as f:\n",
    "            ql1_answers = json.load(f)\n",
    "        with open(ql2_path, 'r', encoding='utf-8') as f:\n",
    "            ql2_answers = json.load(f)\n",
    "        if task != \"equal\":\n",
    "            with open(ql3_path, 'r', encoding='utf-8') as f:\n",
    "                ql3_answers = json.load(f)\n",
    "        else:\n",
    "            ql3_answers = None\n",
    "    except:\n",
    "        print(f\"Error loading files: {ql1_path}, {ql2_path}, {ql3_path}\")   \n",
    "        return None\n",
    "    # Compute metrics per question\n",
    "    similarity_scores = {}\n",
    "    if task == \"minus\":\n",
    "        # For minus task, we need to compare ql1 and ql2 with ql3\n",
    "        for qid, ans3 in ql3_answers.items():\n",
    "            set3 = set(ans3)\n",
    "            #qid = str(int(qid) + 1)\n",
    "            set_a = set(ql1_answers.get(qid, []))\n",
    "            set_b = set(ql2_answers.get(qid, [])) \n",
    "            set_c =  set_a - set_b \n",
    "            sim = jaccard_similarity(set3, set_c)\n",
    "            is_empty = int(len(set3) == 0 and len(set_c) == 0)\n",
    "            binary_eq = int(set_c == set3)\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "    else:\n",
    "        for qid, ans1 in ql1_answers.items():\n",
    "            set1 = set(ans1)\n",
    "            set2 = set(ql2_answers.get(qid, []))\n",
    "            is_empty = int(len(set1) == 0 and len(set2) == 0)\n",
    "            if task == \"equal\":\n",
    "                sim = jaccard_similarity(set1, set2)\n",
    "                binary_eq = int(set1 == set2)\n",
    "            else:\n",
    "                set_c = set(ql3_answers.get(qid, []))\n",
    "                union = set2.union(set_c) \n",
    "                sim = jaccard_similarity(set1, union)\n",
    "                binary_eq = int(is_subset(set2, set1))\n",
    "            similarity_scores[qid] = (sim, is_empty, binary_eq)\n",
    "\n",
    "    # Create DataFrame\n",
    "    sim_df = pd.DataFrame.from_dict(\n",
    "        similarity_scores,\n",
    "        orient='index',\n",
    "        columns=['JaccardSimilarity', 'IsEmptySet', 'BinaryEqual']\n",
    "    )\n",
    "\n",
    "    # Ensure index is a column\n",
    "    sim_df = sim_df.reset_index().rename(columns={'index': 'QuestionID'})\n",
    "\n",
    "    # Save to TSV\n",
    "    output_filename = f'{prefix}{task}_{model}_{action}.tsv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    sim_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Saved similarity results to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a280277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-nano-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-mini-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/equal_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/sup-sub_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n",
      "Saved similarity results to ../data/evaluation_results/spinach/minus_gpt-4.1-2025-04-14_.tsv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = ['gpt-4.1-nano-2025-04-14',\"gpt-4.1-mini-2025-04-14\",\"gpt-4.1-2025-04-14\"]\n",
    "task = ['equal', 'sup-sub', \"minus\"]\n",
    "action = [\"\"]\n",
    "operations = ['zero-shot',\"follow_up_fixing\",\"rel_classification_and_questions\"]\n",
    "datasets = ['spinach']\n",
    "for dataset in datasets:\n",
    "    for m in model:\n",
    "        for t in task:\n",
    "            for a in action:\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                )\n",
    "                compute_similarity(\n",
    "                    model=m,\n",
    "                    task=t,\n",
    "                    action=a,\n",
    "                    base_dir=f'../data/answers/{operations[0]}/{dataset}',\n",
    "                    output_dir=f'../data/evaluation_results/{dataset}',\n",
    "                    star=False\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4337d49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Action</th>\n",
       "      <th>Average_All</th>\n",
       "      <th>Average_NoEmpty</th>\n",
       "      <th>Ratio_empty</th>\n",
       "      <th>Binary_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.9485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>equal</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.3465</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.3664</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.6333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.0667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.4136</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.4933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>minus</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.6211</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.5467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.8173</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.5521</td>\n",
       "      <td>0.5958</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.5906</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.8867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td></td>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.6067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>wikidata</td>\n",
       "      <td>0.4769</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.5733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>classAndAnswer</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sup-sub</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>fixing</td>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.6467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Task                    Model          Action  Average_All  \\\n",
       "0     equal       gpt-4.1-2025-04-14                       0.7438   \n",
       "1     equal       gpt-4.1-2025-04-14        wikidata       0.7980   \n",
       "2     equal       gpt-4.1-2025-04-14  classAndAnswer       0.9249   \n",
       "3     equal       gpt-4.1-2025-04-14          fixing       0.9275   \n",
       "4     equal  gpt-4.1-mini-2025-04-14                       0.7116   \n",
       "5     equal  gpt-4.1-mini-2025-04-14        wikidata       0.7297   \n",
       "6     equal  gpt-4.1-mini-2025-04-14  classAndAnswer       0.8755   \n",
       "7     equal  gpt-4.1-mini-2025-04-14          fixing       0.9138   \n",
       "8     equal  gpt-4.1-nano-2025-04-14                       0.6025   \n",
       "9     equal  gpt-4.1-nano-2025-04-14        wikidata       0.6103   \n",
       "10    equal  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0155   \n",
       "11    equal  gpt-4.1-nano-2025-04-14          fixing       0.6881   \n",
       "12    minus       gpt-4.1-2025-04-14                       0.3465   \n",
       "13    minus       gpt-4.1-2025-04-14        wikidata       0.3664   \n",
       "14    minus       gpt-4.1-2025-04-14  classAndAnswer       0.5240   \n",
       "15    minus       gpt-4.1-2025-04-14          fixing       0.6980   \n",
       "16    minus  gpt-4.1-mini-2025-04-14                       0.2616   \n",
       "17    minus  gpt-4.1-mini-2025-04-14        wikidata       0.2763   \n",
       "18    minus  gpt-4.1-mini-2025-04-14  classAndAnswer       0.4136   \n",
       "19    minus  gpt-4.1-mini-2025-04-14          fixing       0.5816   \n",
       "20    minus  gpt-4.1-nano-2025-04-14                       0.1749   \n",
       "21    minus  gpt-4.1-nano-2025-04-14        wikidata       0.1955   \n",
       "22    minus  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0025   \n",
       "23    minus  gpt-4.1-nano-2025-04-14          fixing       0.2410   \n",
       "24  sup-sub       gpt-4.1-2025-04-14                       0.5839   \n",
       "25  sup-sub       gpt-4.1-2025-04-14        wikidata       0.6200   \n",
       "26  sup-sub       gpt-4.1-2025-04-14  classAndAnswer       0.7628   \n",
       "27  sup-sub       gpt-4.1-2025-04-14          fixing       0.8535   \n",
       "28  sup-sub  gpt-4.1-mini-2025-04-14                       0.5521   \n",
       "29  sup-sub  gpt-4.1-mini-2025-04-14        wikidata       0.5670   \n",
       "30  sup-sub  gpt-4.1-mini-2025-04-14  classAndAnswer       0.6855   \n",
       "31  sup-sub  gpt-4.1-mini-2025-04-14          fixing       0.8074   \n",
       "32  sup-sub  gpt-4.1-nano-2025-04-14                       0.4385   \n",
       "33  sup-sub  gpt-4.1-nano-2025-04-14        wikidata       0.4769   \n",
       "34  sup-sub  gpt-4.1-nano-2025-04-14  classAndAnswer       0.0617   \n",
       "35  sup-sub  gpt-4.1-nano-2025-04-14          fixing       0.4644   \n",
       "\n",
       "    Average_NoEmpty  Ratio_empty  Binary_count  \n",
       "0            0.7748       0.0400        0.4733  \n",
       "1            0.8199       0.0267        0.5000  \n",
       "2            0.9751       0.0515        0.9485  \n",
       "3            0.9730       0.0467        0.9067  \n",
       "4            0.7907       0.1000        0.5067  \n",
       "5            0.7549       0.0333        0.4400  \n",
       "6            0.9800       0.1067        0.9400  \n",
       "7            0.9453       0.0333        0.8533  \n",
       "8            0.7172       0.1600        0.3467  \n",
       "9            0.7042       0.1333        0.3333  \n",
       "10           0.7755       0.9800        0.8333  \n",
       "11           0.9469       0.2733        0.7600  \n",
       "12           0.5414       0.3600        0.1533  \n",
       "13           0.5726       0.3600        0.1667  \n",
       "14           0.7346       0.2867        0.4333  \n",
       "15           0.8512       0.1800        0.6333  \n",
       "16           0.4563       0.4267        0.0933  \n",
       "17           0.4555       0.3933        0.0667  \n",
       "18           0.7050       0.4133        0.4067  \n",
       "19           0.7859       0.2600        0.4933  \n",
       "20           0.4300       0.5933        0.0933  \n",
       "21           0.4190       0.5333        0.0800  \n",
       "22           0.1871       0.9867        0.8000  \n",
       "23           0.6127       0.6067        0.2600  \n",
       "24           0.6211       0.0600        0.5467  \n",
       "25           0.6550       0.0533        0.5667  \n",
       "26           0.8173       0.0667        0.9467  \n",
       "27           0.8890       0.0400        0.9467  \n",
       "28           0.5958       0.0733        0.5067  \n",
       "29           0.5906       0.0400        0.4867  \n",
       "30           0.7674       0.1067        0.9667  \n",
       "31           0.8239       0.0200        0.8867  \n",
       "32           0.5263       0.1667        0.6067  \n",
       "33           0.5379       0.1133        0.5733  \n",
       "34           0.6166       0.9000        0.8400  \n",
       "35           0.7410       0.3733        0.6467  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_evaluation_results(folder):\n",
    "    \"\"\"\n",
    "    Summarize per-question TSV evaluation files in a folder.\n",
    "    Expects filenames in the format: task-model-action.tsv\n",
    "    and each TSV contains columns: QuestionID, JaccardSimilarity, IsEmptySet, BinaryEqual\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if not filename.endswith(\".tsv\"):\n",
    "            continue\n",
    "\n",
    "        # Extract metadata from filename\n",
    "        base = filename[:-4]  # remove .tsv\n",
    "        parts = base.split('_')\n",
    "        task = parts[0]\n",
    "        action = parts[-1]\n",
    "        model = parts[1]\n",
    "\n",
    "        # Read TSV\n",
    "        df = pd.read_csv(os.path.join(folder, filename), sep='\\t')\n",
    "\n",
    "        # Ensure JaccardSimilarity column exists\n",
    "        if 'JaccardSimilarity' not in df.columns:\n",
    "            raise ValueError(f\"Missing 'JaccardSimilarity' in {filename}\")\n",
    "\n",
    "        # Compute overall average\n",
    "        avg_all = df['JaccardSimilarity'].mean()\n",
    "\n",
    "        # Identify empty (zero) Jaccard entries\n",
    "        is_empty = df['JaccardSimilarity'] == 0\n",
    "        ratio_empty = is_empty.mean()\n",
    "\n",
    "        # Average excluding empty entries\n",
    "        non_empty = df.loc[~is_empty, 'JaccardSimilarity']\n",
    "        avg_non_empty = non_empty.mean() if not non_empty.empty else float('nan')\n",
    "\n",
    "        # Binary count: proportion where BinaryEqual == 1\n",
    "        if 'BinaryEqual' in df.columns:\n",
    "            binary_count = (df['BinaryEqual'] == 1).mean()\n",
    "        else:\n",
    "            binary_count = float('nan')\n",
    "\n",
    "        rows.append({\n",
    "            \"Task\": task,\n",
    "            \"Model\": model,\n",
    "            \"Action\": action,\n",
    "            \"Average_All\": round(avg_all, 4),\n",
    "            \"Average_NoEmpty\": round(avg_non_empty, 4),\n",
    "            \"Ratio_empty\": round(ratio_empty, 4),\n",
    "            \"Binary_count\": round(binary_count, 4),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage:\n",
    "df = summarize_evaluation_results(\"../data/evaluation_results/spinach/\")\n",
    "df\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
